{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "End2End-AECNNClassifier-Baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "peWtFSU-e2Su"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b36304c18a704b8299db0ecee1e3ddaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b84540d8b1c84d46a9fcbf7d468172e6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_97877351e44542f2bcb96e644346d051",
              "IPY_MODEL_573257d5c4eb498aaeb247fefcc6b514"
            ]
          }
        },
        "b84540d8b1c84d46a9fcbf7d468172e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97877351e44542f2bcb96e644346d051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3f86c7111eb74bc287f36ad3f3ca83cf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6bf06c932cb64f34a7507456ccb56d01"
          }
        },
        "573257d5c4eb498aaeb247fefcc6b514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_96366268825849eea2f89fd95ee581ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:07&lt;00:00, 22810958.68it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9cf31bd3978a48058c6f3a60c65d91f5"
          }
        },
        "3f86c7111eb74bc287f36ad3f3ca83cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6bf06c932cb64f34a7507456ccb56d01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96366268825849eea2f89fd95ee581ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9cf31bd3978a48058c6f3a60c65d91f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LZPFRgN90KC",
        "colab_type": "text"
      },
      "source": [
        "## Import Libaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSj15dPGylVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data science tools\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "# Torch and Torchvision\n",
        "import torchvision \n",
        "from torch import optim, cuda\n",
        "import torch.nn as nn\n",
        "#from torch.utils import data\n",
        "from torch.utils.data import Dataset, TensorDataset,DataLoader,sampler\n",
        "#from torchvision import datasets\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "\n",
        "# Image manipulations\n",
        "from PIL import Image\n",
        "# Useful for examining network\n",
        "from torchsummary import summary\n",
        "# Timing utility\n",
        "from timeit import default_timer as timer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eapte99R5AVN",
        "colab_type": "code",
        "outputId": "c73513d1-23bd-48cd-fde7-86b1b5817071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "# Visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib inline\n",
        "plt.rcParams['font.size'] = 14\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzPw1X-v99oJ",
        "colab_type": "code",
        "outputId": "50bb124e-96da-4588-e237-a8de080a3e20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "!pip install tensorboardX\n",
        "import tensorflow as tf\n",
        "import scipy.misc\n",
        "from tensorboardX import SummaryWriter\n",
        "%load_ext tensorboard\n",
        "logs_base_dir = \"Logs\"\n",
        "os.makedirs(logs_base_dir, exist_ok=True)\n",
        "# debug ref: https://github.com/pytorch/pytorch/issues/22676"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 28.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 92kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 194kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.3)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (46.1.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8PhQbYUfY_s",
        "colab_type": "code",
        "outputId": "cc9d3440-8dcd-431c-91ab-8cfb754f5095",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "b36304c18a704b8299db0ecee1e3ddaf",
            "b84540d8b1c84d46a9fcbf7d468172e6",
            "97877351e44542f2bcb96e644346d051",
            "573257d5c4eb498aaeb247fefcc6b514",
            "3f86c7111eb74bc287f36ad3f3ca83cf",
            "6bf06c932cb64f34a7507456ccb56d01",
            "96366268825849eea2f89fd95ee581ef",
            "9cf31bd3978a48058c6f3a60c65d91f5"
          ]
        }
      },
      "source": [
        "# import Customed dataloader \n",
        "import DataPreparation  \n",
        "\n",
        "trainset = DataPreparation.trainset \n",
        "dataloaders = DataPreparation.dataloaders "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b36304c18a704b8299db0ecee1e3ddaf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "50000 10000\n",
            "\n",
            "(50000, 3, 32, 32)\n",
            "train_mean [0.4914009  0.48215896 0.4465308 ]\n",
            "train_std [0.24703279 0.24348423 0.26158753]\n",
            "Filter 50% of the labels for training (bird, deer and truck\n",
            "length of customed training data 42500\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdkBulgM4Vkv",
        "colab_type": "text"
      },
      "source": [
        "## Build&Train Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWKUCA0aTnFm",
        "colab_type": "code",
        "outputId": "0fdeef40-f21b-4698-9f4f-90f92226ec77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        }
      },
      "source": [
        "class EndtoEndModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EndtoEndModel, self).__init__()\n",
        "        \n",
        "        # batch_size : 32\n",
        "        # Input size to the Autoencoder : [batch_size, 3, 32, 32]\n",
        "        # Output size from the Autoencoder : [batch_size, 3, 32, 32]\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels = 3, out_channels = 6, kernel_size = 3, stride=1, padding=1), \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels = 6, out_channels = 12, kernel_size = 3, stride=1, padding=1), \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels = 12, out_channels = 24, kernel_size = 3, stride=2, padding=1), \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels = 24, out_channels = 48, kernel_size = 3, stride=2, padding=1),\n",
        "            nn.ReLU() \n",
        "            ## Output size : [batch_size, 48, 16, 16]\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            # For Upscaling :\n",
        "            # 2x2 kernels can only learn nearest pixel upscaling.\n",
        "            # 3x3 kernels can do bilinear but will require asymmetric padding.\n",
        "            # But 4x4 can do bilinear again without asymmetrical padding.\n",
        "          \n",
        "            nn.ConvTranspose2d(in_channels =48, out_channels =24, kernel_size =4, stride=2, padding=1), \n",
        "            nn.ReLU(),  #TODO : try with LeakyReLU while decoding\n",
        "            nn.ConvTranspose2d(in_channels =24, out_channels =12, kernel_size =4, stride=2, padding=1), \n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels =12, out_channels =6, kernel_size =3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels =6, out_channels =3, kernel_size =3, stride=1, padding=1),  \n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.classifier_conv_layer = nn.Sequential(\n",
        "\n",
        "            # xiaoya: no Relu\n",
        "            nn.Conv2d(in_channels=48, out_channels=48, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(48),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=48, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=0.05), # TODO experiment with 0.2/0.4\n",
        "               \n",
        "        )\n",
        "        self.classifier_fc_layer = nn.Sequential(\n",
        "            nn.Linear(512, 128),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(32, 10)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        #autoencoder branch\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        # classifier branch\n",
        "        # conv layers\n",
        "        x = self.classifier_conv_layer(encoded)       \n",
        "        # flatten)\n",
        "        x = x.view(x.size(0), -1) \n",
        "        #print(x.size())      \n",
        "        # fc layer\n",
        "        x = self.classifier_fc_layer(x)\n",
        "        return decoded,x\n",
        "def toGPU(x):\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "    return x\n",
        "def create_model():\n",
        "    model = EndtoEndModel()\n",
        "    model = toGPU(model)\n",
        "    return model\n",
        "model=create_model()\n",
        "summary(model, input_size=(3, 32, 32), batch_size=32, device='cuda')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [32, 6, 32, 32]             168\n",
            "              ReLU-2            [32, 6, 32, 32]               0\n",
            "            Conv2d-3           [32, 12, 32, 32]             660\n",
            "              ReLU-4           [32, 12, 32, 32]               0\n",
            "            Conv2d-5           [32, 24, 16, 16]           2,616\n",
            "              ReLU-6           [32, 24, 16, 16]               0\n",
            "            Conv2d-7             [32, 48, 8, 8]          10,416\n",
            "              ReLU-8             [32, 48, 8, 8]               0\n",
            "   ConvTranspose2d-9           [32, 24, 16, 16]          18,456\n",
            "             ReLU-10           [32, 24, 16, 16]               0\n",
            "  ConvTranspose2d-11           [32, 12, 32, 32]           4,620\n",
            "             ReLU-12           [32, 12, 32, 32]               0\n",
            "  ConvTranspose2d-13            [32, 6, 32, 32]             654\n",
            "             ReLU-14            [32, 6, 32, 32]               0\n",
            "  ConvTranspose2d-15            [32, 3, 32, 32]             165\n",
            "          Sigmoid-16            [32, 3, 32, 32]               0\n",
            "           Conv2d-17             [32, 48, 8, 8]          20,784\n",
            "      BatchNorm2d-18             [32, 48, 8, 8]              96\n",
            "             ReLU-19             [32, 48, 8, 8]               0\n",
            "           Conv2d-20             [32, 32, 8, 8]          13,856\n",
            "             ReLU-21             [32, 32, 8, 8]               0\n",
            "        MaxPool2d-22             [32, 32, 4, 4]               0\n",
            "           Conv2d-23             [32, 32, 4, 4]           9,248\n",
            "      BatchNorm2d-24             [32, 32, 4, 4]              64\n",
            "             ReLU-25             [32, 32, 4, 4]               0\n",
            "        Dropout2d-26             [32, 32, 4, 4]               0\n",
            "           Linear-27                  [32, 128]          65,664\n",
            "          Dropout-28                  [32, 128]               0\n",
            "             ReLU-29                  [32, 128]               0\n",
            "           Linear-30                   [32, 64]           8,256\n",
            "             ReLU-31                   [32, 64]               0\n",
            "           Linear-32                   [32, 32]           2,080\n",
            "             ReLU-33                   [32, 32]               0\n",
            "           Linear-34                   [32, 10]             330\n",
            "================================================================\n",
            "Total params: 158,133\n",
            "Trainable params: 158,133\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.38\n",
            "Forward/backward pass size (MB): 31.02\n",
            "Params size (MB): 0.60\n",
            "Estimated Total Size (MB): 32.00\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01xjkO8DelS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peWtFSU-e2Su",
        "colab_type": "text"
      },
      "source": [
        "##### original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHyX4SHnBQvo",
        "colab_type": "code",
        "outputId": "d68614a9-3c8d-4938-9e61-60e73b54dd95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        }
      },
      "source": [
        "class EndtoEndModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EndtoEndModel, self).__init__()\n",
        "        \n",
        "        # batch_size : 32\n",
        "        # Input size to the Autoencoder : [batch_size, 3, 32, 32]\n",
        "        # Output size from the Autoencoder : [batch_size, 3, 32, 32]\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels = 3, out_channels = 12, kernel_size = 4, stride=2, padding=1), \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels = 12, out_channels = 24, kernel_size = 4, stride=2, padding=1), \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels = 24, out_channels = 48, kernel_size = 4, stride=2, padding=1),\n",
        "            nn.ReLU() \n",
        "            ## Output size : [batch_size, 48, 16, 16]\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            # For Upscaling :\n",
        "            # 2x2 kernels can only learn nearest pixel upscaling.\n",
        "            # 3x3 kernels can do bilinear but will require asymmetric padding.\n",
        "            # But 4x4 can do bilinear again without asymmetrical padding.\n",
        "          \n",
        "            nn.ConvTranspose2d(in_channels =48, out_channels =24, kernel_size =4, stride=2, padding=1), \n",
        "            nn.ReLU(),  #TODO : try with LeakyReLU while decoding\n",
        "            nn.ConvTranspose2d(in_channels =24, out_channels =12, kernel_size =4, stride=2, padding=1), \n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels =12, out_channels =3, kernel_size =4, stride=2, padding=1), \n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.classifier_conv_layer = nn.Sequential(\n",
        "\n",
        "            # xiaoya: no Relu\n",
        "            nn.Conv2d(in_channels=48, out_channels=48, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(48),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=48, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=0.05), # TODO experiment with 0.2/0.4\n",
        "               \n",
        "        )\n",
        "        self.classifier_fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(128, 64),        \n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(32, 10)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        #autoencoder branch\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        # classifier branch\n",
        "        # conv layers\n",
        "        x = self.classifier_conv_layer(encoded)       \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)        \n",
        "        # fc layer\n",
        "        x = self.classifier_fc_layer(x)\n",
        "        return decoded,x\n",
        "def toGPU(x):\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "    return x\n",
        "def create_model():\n",
        "    model = EndtoEndModel()\n",
        "    model = toGPU(model)\n",
        "    return model\n",
        "model=create_model()\n",
        "summary(model, input_size=(3, 32, 32), batch_size=32, device='cuda')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [32, 12, 16, 16]             588\n",
            "              ReLU-2           [32, 12, 16, 16]               0\n",
            "            Conv2d-3             [32, 24, 8, 8]           4,632\n",
            "              ReLU-4             [32, 24, 8, 8]               0\n",
            "            Conv2d-5             [32, 48, 4, 4]          18,480\n",
            "              ReLU-6             [32, 48, 4, 4]               0\n",
            "   ConvTranspose2d-7             [32, 24, 8, 8]          18,456\n",
            "              ReLU-8             [32, 24, 8, 8]               0\n",
            "   ConvTranspose2d-9           [32, 12, 16, 16]           4,620\n",
            "             ReLU-10           [32, 12, 16, 16]               0\n",
            "  ConvTranspose2d-11            [32, 3, 32, 32]             579\n",
            "          Sigmoid-12            [32, 3, 32, 32]               0\n",
            "           Conv2d-13             [32, 48, 4, 4]          20,784\n",
            "      BatchNorm2d-14             [32, 48, 4, 4]              96\n",
            "             ReLU-15             [32, 48, 4, 4]               0\n",
            "           Conv2d-16             [32, 32, 4, 4]          13,856\n",
            "             ReLU-17             [32, 32, 4, 4]               0\n",
            "        MaxPool2d-18             [32, 32, 2, 2]               0\n",
            "           Conv2d-19             [32, 32, 2, 2]           9,248\n",
            "      BatchNorm2d-20             [32, 32, 2, 2]              64\n",
            "             ReLU-21             [32, 32, 2, 2]               0\n",
            "        Dropout2d-22             [32, 32, 2, 2]               0\n",
            "          Dropout-23                  [32, 128]               0\n",
            "           Linear-24                   [32, 64]           8,256\n",
            "             ReLU-25                   [32, 64]               0\n",
            "           Linear-26                   [32, 32]           2,080\n",
            "             ReLU-27                   [32, 32]               0\n",
            "           Linear-28                   [32, 10]             330\n",
            "================================================================\n",
            "Total params: 102,069\n",
            "Trainable params: 102,069\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.38\n",
            "Forward/backward pass size (MB): 7.42\n",
            "Params size (MB): 0.39\n",
            "Estimated Total Size (MB): 8.19\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC5B0QELONdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8IcYz-Oet7L",
        "colab_type": "text"
      },
      "source": [
        "####mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXC8xWj2exZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCPvQFK7W6Q9",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSE4MMXoWS47",
        "colab_type": "text"
      },
      "source": [
        "### Function for Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKA8-TyDW93q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model,\n",
        "          train_loader,\n",
        "          valid_loader,\n",
        "          save_file_name,\n",
        "          max_epochs_stop=3,\n",
        "          n_epochs=20,\n",
        "          print_every=1,\n",
        "          weight_loss_ae =1 , \n",
        "          weight_loss_clf =1,          \n",
        "          criterionAE = nn.MSELoss(),\n",
        "          criterionCLF = nn.CrossEntropyLoss(),\n",
        "          optimizer = optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-5) \n",
        "    ):\n",
        "    \"\"\"Train an end to end AutoencoderClassification Model\n",
        "\n",
        "    Params Explained\n",
        "    --------\n",
        "        model (PyTorch model): cnn to train\n",
        "        train_loader (PyTorch dataloader): training dataloader to iterate through\n",
        "        valid_loader (PyTorch dataloader): validation dataloader used for early stopping\n",
        "        save_file_name (str ending in '.pkl'): file path to save the model state dict\n",
        "        max_epochs_stop (int): maximum number of epochs with no improvement in validation loss for early stopping\n",
        "        n_epochs (int): maximum number of training epochs\n",
        "        weight_loss_ae(int) : the weights of criterionAE in our objective to minimize the loss\n",
        "        weight_loss_clf(int):  the weights of criterionCLF in our objective to minimize the lo\n",
        "        print_every (int): frequency of epochs to print training stats\n",
        "        criterionAE (PyTorch loss): objective to minimize for the Autoencoder branch\n",
        "        criterionCLF (PyTorch loss): objective to minimize for the classifier branch\n",
        "        optimizer (PyTorch optimizier): optimizer to compute gradients of model parameters\n",
        "    Returns\n",
        "    --------\n",
        "        model (PyTorch model): trained Model \n",
        "        history (DataFrame): history of train and validation losses and accuracy\n",
        "    \"\"\"\n",
        "    # Early stopping intialization\n",
        "    epochs_no_improve = 0\n",
        "    valid_loss_min = np.Inf\n",
        "\n",
        "    valid_max_acc = 0\n",
        "    history = []\n",
        "\n",
        "    # Number of epochs already trained (if using loaded in model weights)\n",
        "    try:\n",
        "        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n",
        "    except:\n",
        "        model.epochs = 0\n",
        "        print(f'Starting Training from Scratch.\\n')\n",
        "\n",
        "    overall_start = timer()\n",
        "\n",
        "    # Main loop\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        # keep track of training and validation loss each epoch\n",
        "        train_loss = 0.0\n",
        "        train_AEloss = 0.0\n",
        "        train_CLFloss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        valid_AEloss = 0.0\n",
        "        valid_CLFloss = 0.0\n",
        "        train_acc = 0\n",
        "        valid_acc = 0\n",
        "\n",
        "        # Set to training\n",
        "        model.train()\n",
        "        start = timer()\n",
        "\n",
        "        # Training loop\n",
        "        for num, (data, target) in enumerate(train_loader):\n",
        "            # Tensors to gpu\n",
        "            data, target = toGPU(data),toGPU(target)\n",
        "\n",
        "            # Clear gradients\n",
        "            optimizer.zero_grad()\n",
        "            # load model\n",
        "            encoded, output = model(data)\n",
        "\n",
        "            # Loss and backpropagation of gradients\n",
        "            AEloss = criterionAE(encoded, data)\n",
        "\n",
        "            CLFloss = criterionCLF(output,target)\n",
        "            loss = weight_loss_ae*AEloss + weight_loss_clf*CLFloss\n",
        "            \n",
        "            loss.backward()\n",
        "\n",
        "            # Update the parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track train loss by multiplying average loss by number of examples in batch\n",
        "            train_loss += loss * data.size(0)\n",
        "            train_AEloss += AEloss.item() * data.size(0)\n",
        "            train_CLFloss += CLFloss.item() * data.size(0)\n",
        "            # Calculate accuracy by finding max log probability\n",
        "            _, pred = torch.max(output, dim=1)\n",
        "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "            # Need to convert correct tensor from int to float to average\n",
        "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
        "            # Multiply average accuracy times the number of examples in batch\n",
        "            train_acc += accuracy.item() * data.size(0)\n",
        "\n",
        "            # Track training progress\n",
        "            print(\n",
        "                f'Epoch: {epoch}\\t{100 * (num + 1) / len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n",
        "                end='\\r')\n",
        "\n",
        "        # After training loops ends, start validation\n",
        "        #else:\n",
        "        model.epochs += 1\n",
        "\n",
        "        # Don't need to keep track of gradients\n",
        "        with torch.no_grad():\n",
        "            # Set to evaluation mode\n",
        "            model.eval()\n",
        "\n",
        "            # Validation loop\n",
        "            for data, target in valid_loader:\n",
        "                # Tensors to gpu\n",
        "                if torch.cuda.is_available():\n",
        "                    data, target = data.cuda(), target.cuda()\n",
        "                # Forward pass\n",
        "                encoded, output = model(data)\n",
        "\n",
        "                # Validation loss\n",
        "                AEloss = criterionAE(encoded, data)\n",
        "\n",
        "                CLFloss = criterionCLF(output,target)\n",
        "                loss = weight_loss_ae*AEloss + weight_loss_clf*CLFloss\n",
        "                \n",
        "                # Multiply average loss times the number of examples in batch\n",
        "                valid_loss += loss * data.size(0)\n",
        "                valid_AEloss += AEloss.item() * data.size(0)\n",
        "                valid_CLFloss += CLFloss.item() * data.size(0)\n",
        "                # Calculate validation accuracy\n",
        "                _, pred = torch.max(output, dim=1)\n",
        "                correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "                accuracy = torch.mean(\n",
        "                    correct_tensor.type(torch.FloatTensor))\n",
        "                # Multiply average accuracy times the number of examples\n",
        "                valid_acc += accuracy.item() * data.size(0)\n",
        "\n",
        "            # Calculate average losses\n",
        "            train_loss = train_loss / len(train_loader.dataset)\n",
        "            valid_loss = valid_loss / len(valid_loader.dataset)\n",
        "            train_AEloss = train_AEloss / len(train_loader.dataset)\n",
        "            valid_AEloss = valid_AEloss / len(valid_loader.dataset)\n",
        "            train_CLFloss = train_CLFloss / len(train_loader.dataset)\n",
        "            valid_CLFloss = valid_CLFloss / len(valid_loader.dataset)            \n",
        "            # Calculate average accuracy\n",
        "            train_acc = train_acc / len(train_loader.dataset)\n",
        "            valid_acc = valid_acc / len(valid_loader.dataset)\n",
        "\n",
        "            history.append(\n",
        "                [train_loss.item(), valid_loss.item(), train_acc, valid_acc,train_AEloss,valid_AEloss,train_CLFloss,valid_CLFloss]\n",
        "                )\n",
        "\n",
        "            # Print training and validation results\n",
        "            if (epoch + 1) % print_every == 0:\n",
        "                print(\n",
        "                    f'\\nEpoch: {epoch}'\n",
        "                )\n",
        "                print(\n",
        "                    f'\\t\\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n",
        "                    )\n",
        "                print(\n",
        "                    f'\\t\\tTraining AELoss: {train_AEloss:.4f} \\tValidation AELoss: {valid_AEloss:.4f}'\n",
        "                )\n",
        "                print(\n",
        "                    f'\\t\\tTraining CLFLoss: {train_CLFloss:.4f} \\tValidation CLFLoss: {valid_CLFloss:.4f}'\n",
        "                )\n",
        "                print(\n",
        "                    f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n",
        "                )\n",
        "\n",
        "            # Save the model if validation loss decreases\n",
        "            if valid_loss < valid_loss_min:\n",
        "                # Save model\n",
        "                torch.save(model.state_dict(), save_file_name)\n",
        "                # Track improvement\n",
        "                epochs_no_improve = 0\n",
        "                valid_loss_min = valid_loss\n",
        "                valid_best_acc = valid_acc\n",
        "                best_epoch = epoch\n",
        "\n",
        "            # Otherwise increment count of epochs with no improvement\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "                # Trigger early stopping\n",
        "                if epochs_no_improve >= max_epochs_stop:\n",
        "                    print(\n",
        "                        f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
        "                    )\n",
        "                    total_time = timer() - overall_start\n",
        "                    print(\n",
        "                        f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n",
        "                    )\n",
        "\n",
        "                    # Load the best state dict\n",
        "                    model.load_state_dict(torch.load(save_file_name))\n",
        "                    # Attach the optimizer\n",
        "                    model.optimizer = optimizer\n",
        "\n",
        "                    # Format history\n",
        "                    history = pd.DataFrame(\n",
        "                        history,\n",
        "                        columns=[\n",
        "                            'train_loss', 'valid_loss', 'train_acc',\n",
        "                            'valid_acc','train_AEloss','valid_AEloss',\n",
        "                            'train_CLFloss','valid_CLFloss'\n",
        "                        ])\n",
        "                    return model, history\n",
        "\n",
        "    # Attach the optimizer\n",
        "    model.optimizer = optimizer\n",
        "    # Record overall time and print out stats\n",
        "    total_time = timer() - overall_start\n",
        "    print(\n",
        "        f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
        "    )\n",
        "    print(\n",
        "        f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.'\n",
        "    )\n",
        "    # Format history\n",
        "    history = pd.DataFrame(\n",
        "        history,\n",
        "        columns=['train_loss', 'valid_loss', 'train_acc', \n",
        "                 'valid_acc','train_AEloss','valid_AEloss',\n",
        "                 'train_CLFloss','valid_CLFloss'])\n",
        "    return model, history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WghfVTfXFLG",
        "colab_type": "text"
      },
      "source": [
        "### Training history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ccbl_DK4hmRZ",
        "colab_type": "code",
        "outputId": "ffd7670b-2e58-4315-dcc8-1639aebb0f3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_output, history = train(\n",
        "    model,\n",
        "    dataloaders['train'],\n",
        "    dataloaders['val'],\n",
        "    save_file_name='end2en.pkl',\n",
        "    max_epochs_stop=30,\n",
        "    n_epochs=30)\n",
        "\n",
        "history.to_csv('history.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model has been trained for: 10 epochs.\n",
            "\n",
            "\n",
            "Epoch: 0\n",
            "\t\tTraining Loss: 1.4155 \tValidation Loss: 1.3877\n",
            "\t\tTraining AELoss: 0.6628 \tValidation Loss: 0.5383\n",
            "\t\tTraining CLFLoss: 0.7527 \tValidation Loss: 0.8494\n",
            "\t\tTraining Accuracy: 73.79%\t Validation Accuracy: 70.96%\n",
            "\n",
            "Epoch: 1\n",
            "\t\tTraining Loss: 1.4019 \tValidation Loss: 1.3828\n",
            "\t\tTraining AELoss: 0.6634 \tValidation Loss: 0.5371\n",
            "\t\tTraining CLFLoss: 0.7385 \tValidation Loss: 0.8457\n",
            "\t\tTraining Accuracy: 74.34%\t Validation Accuracy: 70.98%\n",
            "\n",
            "Epoch: 2\n",
            "\t\tTraining Loss: 1.3849 \tValidation Loss: 1.3624\n",
            "\t\tTraining AELoss: 0.6637 \tValidation Loss: 0.5381\n",
            "\t\tTraining CLFLoss: 0.7211 \tValidation Loss: 0.8243\n",
            "\t\tTraining Accuracy: 74.72%\t Validation Accuracy: 72.28%\n",
            "\n",
            "Epoch: 3\n",
            "\t\tTraining Loss: 1.3645 \tValidation Loss: 1.3079\n",
            "\t\tTraining AELoss: 0.6631 \tValidation Loss: 0.5382\n",
            "\t\tTraining CLFLoss: 0.7014 \tValidation Loss: 0.7697\n",
            "\t\tTraining Accuracy: 75.60%\t Validation Accuracy: 74.04%\n",
            "\n",
            "Epoch: 4\n",
            "\t\tTraining Loss: 1.3508 \tValidation Loss: 1.3070\n",
            "\t\tTraining AELoss: 0.6630 \tValidation Loss: 0.5372\n",
            "\t\tTraining CLFLoss: 0.6878 \tValidation Loss: 0.7699\n",
            "\t\tTraining Accuracy: 75.92%\t Validation Accuracy: 73.30%\n",
            "\n",
            "Epoch: 5\n",
            "\t\tTraining Loss: 1.3355 \tValidation Loss: 1.3104\n",
            "\t\tTraining AELoss: 0.6623 \tValidation Loss: 0.5367\n",
            "\t\tTraining CLFLoss: 0.6732 \tValidation Loss: 0.7737\n",
            "\t\tTraining Accuracy: 76.55%\t Validation Accuracy: 73.68%\n",
            "\n",
            "Epoch: 6\n",
            "\t\tTraining Loss: 1.3266 \tValidation Loss: 1.3626\n",
            "\t\tTraining AELoss: 0.6626 \tValidation Loss: 0.5375\n",
            "\t\tTraining CLFLoss: 0.6640 \tValidation Loss: 0.8251\n",
            "\t\tTraining Accuracy: 76.69%\t Validation Accuracy: 72.84%\n",
            "\n",
            "Epoch: 7\n",
            "\t\tTraining Loss: 1.3109 \tValidation Loss: 1.2795\n",
            "\t\tTraining AELoss: 0.6620 \tValidation Loss: 0.5375\n",
            "\t\tTraining CLFLoss: 0.6489 \tValidation Loss: 0.7420\n",
            "\t\tTraining Accuracy: 77.24%\t Validation Accuracy: 74.42%\n",
            "\n",
            "Epoch: 8\n",
            "\t\tTraining Loss: 1.3012 \tValidation Loss: 1.3077\n",
            "\t\tTraining AELoss: 0.6623 \tValidation Loss: 0.5370\n",
            "\t\tTraining CLFLoss: 0.6390 \tValidation Loss: 0.7707\n",
            "\t\tTraining Accuracy: 77.84%\t Validation Accuracy: 73.94%\n",
            "\n",
            "Epoch: 9\n",
            "\t\tTraining Loss: 1.2902 \tValidation Loss: 1.2843\n",
            "\t\tTraining AELoss: 0.6617 \tValidation Loss: 0.5366\n",
            "\t\tTraining CLFLoss: 0.6285 \tValidation Loss: 0.7477\n",
            "\t\tTraining Accuracy: 78.39%\t Validation Accuracy: 75.42%\n",
            "\n",
            "Epoch: 10\n",
            "\t\tTraining Loss: 1.2804 \tValidation Loss: 1.2598\n",
            "\t\tTraining AELoss: 0.6616 \tValidation Loss: 0.5361\n",
            "\t\tTraining CLFLoss: 0.6189 \tValidation Loss: 0.7237\n",
            "\t\tTraining Accuracy: 78.31%\t Validation Accuracy: 75.70%\n",
            "\n",
            "Epoch: 11\n",
            "\t\tTraining Loss: 1.2734 \tValidation Loss: 1.3078\n",
            "\t\tTraining AELoss: 0.6617 \tValidation Loss: 0.5368\n",
            "\t\tTraining CLFLoss: 0.6118 \tValidation Loss: 0.7711\n",
            "\t\tTraining Accuracy: 78.77%\t Validation Accuracy: 74.08%\n",
            "\n",
            "Epoch: 12\n",
            "\t\tTraining Loss: 1.2630 \tValidation Loss: 1.2573\n",
            "\t\tTraining AELoss: 0.6618 \tValidation Loss: 0.5358\n",
            "\t\tTraining CLFLoss: 0.6012 \tValidation Loss: 0.7215\n",
            "\t\tTraining Accuracy: 79.11%\t Validation Accuracy: 75.68%\n",
            "\n",
            "Epoch: 13\n",
            "\t\tTraining Loss: 1.2576 \tValidation Loss: 1.2618\n",
            "\t\tTraining AELoss: 0.6616 \tValidation Loss: 0.5364\n",
            "\t\tTraining CLFLoss: 0.5961 \tValidation Loss: 0.7254\n",
            "\t\tTraining Accuracy: 79.19%\t Validation Accuracy: 75.22%\n",
            "\n",
            "Epoch: 14\n",
            "\t\tTraining Loss: 1.2475 \tValidation Loss: 1.2571\n",
            "\t\tTraining AELoss: 0.6607 \tValidation Loss: 0.5366\n",
            "\t\tTraining CLFLoss: 0.5868 \tValidation Loss: 0.7205\n",
            "\t\tTraining Accuracy: 79.54%\t Validation Accuracy: 76.10%\n",
            "\n",
            "Epoch: 15\n",
            "\t\tTraining Loss: 1.2371 \tValidation Loss: 1.2489\n",
            "\t\tTraining AELoss: 0.6610 \tValidation Loss: 0.5353\n",
            "\t\tTraining CLFLoss: 0.5761 \tValidation Loss: 0.7136\n",
            "\t\tTraining Accuracy: 79.95%\t Validation Accuracy: 76.78%\n",
            "\n",
            "Epoch: 16\n",
            "\t\tTraining Loss: 1.2373 \tValidation Loss: 1.2579\n",
            "\t\tTraining AELoss: 0.6617 \tValidation Loss: 0.5353\n",
            "\t\tTraining CLFLoss: 0.5755 \tValidation Loss: 0.7226\n",
            "\t\tTraining Accuracy: 79.86%\t Validation Accuracy: 75.58%\n",
            "\n",
            "Epoch: 17\n",
            "\t\tTraining Loss: 1.2251 \tValidation Loss: 1.2141\n",
            "\t\tTraining AELoss: 0.6613 \tValidation Loss: 0.5355\n",
            "\t\tTraining CLFLoss: 0.5638 \tValidation Loss: 0.6785\n",
            "\t\tTraining Accuracy: 80.42%\t Validation Accuracy: 77.40%\n",
            "\n",
            "Epoch: 18\n",
            "\t\tTraining Loss: 1.2261 \tValidation Loss: 1.2262\n",
            "\t\tTraining AELoss: 0.6613 \tValidation Loss: 0.5356\n",
            "\t\tTraining CLFLoss: 0.5648 \tValidation Loss: 0.6906\n",
            "\t\tTraining Accuracy: 80.41%\t Validation Accuracy: 77.16%\n",
            "\n",
            "Epoch: 19\n",
            "\t\tTraining Loss: 1.2170 \tValidation Loss: 1.2379\n",
            "\t\tTraining AELoss: 0.6617 \tValidation Loss: 0.5361\n",
            "\t\tTraining CLFLoss: 0.5553 \tValidation Loss: 0.7018\n",
            "\t\tTraining Accuracy: 80.79%\t Validation Accuracy: 76.88%\n",
            "\n",
            "Epoch: 20\n",
            "\t\tTraining Loss: 1.2094 \tValidation Loss: 1.2700\n",
            "\t\tTraining AELoss: 0.6611 \tValidation Loss: 0.5360\n",
            "\t\tTraining CLFLoss: 0.5484 \tValidation Loss: 0.7340\n",
            "\t\tTraining Accuracy: 80.73%\t Validation Accuracy: 75.86%\n",
            "\n",
            "Epoch: 21\n",
            "\t\tTraining Loss: 1.2032 \tValidation Loss: 1.2254\n",
            "\t\tTraining AELoss: 0.6619 \tValidation Loss: 0.5358\n",
            "\t\tTraining CLFLoss: 0.5413 \tValidation Loss: 0.6896\n",
            "\t\tTraining Accuracy: 81.14%\t Validation Accuracy: 77.02%\n",
            "\n",
            "Epoch: 22\n",
            "\t\tTraining Loss: 1.1998 \tValidation Loss: 1.2232\n",
            "\t\tTraining AELoss: 0.6615 \tValidation Loss: 0.5360\n",
            "\t\tTraining CLFLoss: 0.5383 \tValidation Loss: 0.6872\n",
            "\t\tTraining Accuracy: 81.14%\t Validation Accuracy: 76.76%\n",
            "\n",
            "Epoch: 23\n",
            "\t\tTraining Loss: 1.1900 \tValidation Loss: 1.2300\n",
            "\t\tTraining AELoss: 0.6611 \tValidation Loss: 0.5355\n",
            "\t\tTraining CLFLoss: 0.5289 \tValidation Loss: 0.6945\n",
            "\t\tTraining Accuracy: 81.53%\t Validation Accuracy: 77.22%\n",
            "\n",
            "Epoch: 24\n",
            "\t\tTraining Loss: 1.1927 \tValidation Loss: 1.2156\n",
            "\t\tTraining AELoss: 0.6612 \tValidation Loss: 0.5349\n",
            "\t\tTraining CLFLoss: 0.5315 \tValidation Loss: 0.6807\n",
            "\t\tTraining Accuracy: 81.55%\t Validation Accuracy: 77.36%\n",
            "\n",
            "Epoch: 25\n",
            "\t\tTraining Loss: 1.1820 \tValidation Loss: 1.1984\n",
            "\t\tTraining AELoss: 0.6614 \tValidation Loss: 0.5366\n",
            "\t\tTraining CLFLoss: 0.5206 \tValidation Loss: 0.6618\n",
            "\t\tTraining Accuracy: 81.75%\t Validation Accuracy: 77.78%\n",
            "\n",
            "Epoch: 26\n",
            "\t\tTraining Loss: 1.1745 \tValidation Loss: 1.2541\n",
            "\t\tTraining AELoss: 0.6612 \tValidation Loss: 0.5356\n",
            "\t\tTraining CLFLoss: 0.5133 \tValidation Loss: 0.7185\n",
            "\t\tTraining Accuracy: 82.00%\t Validation Accuracy: 77.20%\n",
            "\n",
            "Epoch: 27\n",
            "\t\tTraining Loss: 1.1753 \tValidation Loss: 1.2704\n",
            "\t\tTraining AELoss: 0.6610 \tValidation Loss: 0.5360\n",
            "\t\tTraining CLFLoss: 0.5143 \tValidation Loss: 0.7344\n",
            "\t\tTraining Accuracy: 82.15%\t Validation Accuracy: 76.18%\n",
            "\n",
            "Epoch: 28\n",
            "\t\tTraining Loss: 1.1665 \tValidation Loss: 1.2214\n",
            "\t\tTraining AELoss: 0.6609 \tValidation Loss: 0.5361\n",
            "\t\tTraining CLFLoss: 0.5057 \tValidation Loss: 0.6853\n",
            "\t\tTraining Accuracy: 82.54%\t Validation Accuracy: 77.66%\n",
            "\n",
            "Epoch: 29\n",
            "\t\tTraining Loss: 1.1693 \tValidation Loss: 1.1903\n",
            "\t\tTraining AELoss: 0.6614 \tValidation Loss: 0.5357\n",
            "\t\tTraining CLFLoss: 0.5079 \tValidation Loss: 0.6546\n",
            "\t\tTraining Accuracy: 82.42%\t Validation Accuracy: 78.38%\n",
            "\n",
            "Best epoch: 29 with loss: 1.19 and acc: 78.38%\n",
            "1244.03 total seconds elapsed. 42.90 seconds per epoch.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VcNwjVrpkzu",
        "colab_type": "code",
        "outputId": "d95ce8d0-8f1b-4b67-be60-e776bd50d5ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_output, history = train(\n",
        "    model,\n",
        "    dataloaders['train'],\n",
        "    dataloaders['val'],\n",
        "    save_file_name='end2en-40-60.pkl',\n",
        "    max_epochs_stop=30,\n",
        "    n_epochs=20)\n",
        "\n",
        "history.to_csv('history.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model has been trained for: 40 epochs.\n",
            "\n",
            "\n",
            "Epoch: 0\n",
            "\t\tTraining Loss: 1.1621 \tValidation Loss: 1.2044\n",
            "\t\tTraining AELoss: 0.6610 \tValidation Loss: 0.5355\n",
            "\t\tTraining CLFLoss: 0.5011 \tValidation Loss: 0.6689\n",
            "\t\tTraining Accuracy: 82.47%\t Validation Accuracy: 77.36%\n",
            "\n",
            "Epoch: 1\n",
            "\t\tTraining Loss: 1.1576 \tValidation Loss: 1.1977\n",
            "\t\tTraining AELoss: 0.6610 \tValidation Loss: 0.5354\n",
            "\t\tTraining CLFLoss: 0.4967 \tValidation Loss: 0.6623\n",
            "\t\tTraining Accuracy: 82.64%\t Validation Accuracy: 78.08%\n",
            "\n",
            "Epoch: 2\n",
            "\t\tTraining Loss: 1.1566 \tValidation Loss: 1.2293\n",
            "\t\tTraining AELoss: 0.6610 \tValidation Loss: 0.5348\n",
            "\t\tTraining CLFLoss: 0.4955 \tValidation Loss: 0.6944\n",
            "\t\tTraining Accuracy: 82.60%\t Validation Accuracy: 77.50%\n",
            "\n",
            "Epoch: 3\n",
            "\t\tTraining Loss: 1.1499 \tValidation Loss: 1.2330\n",
            "\t\tTraining AELoss: 0.6605 \tValidation Loss: 0.5364\n",
            "\t\tTraining CLFLoss: 0.4893 \tValidation Loss: 0.6965\n",
            "\t\tTraining Accuracy: 82.96%\t Validation Accuracy: 77.66%\n",
            "\n",
            "Epoch: 4\n",
            "\t\tTraining Loss: 1.1469 \tValidation Loss: 1.1973\n",
            "\t\tTraining AELoss: 0.6606 \tValidation Loss: 0.5352\n",
            "\t\tTraining CLFLoss: 0.4862 \tValidation Loss: 0.6622\n",
            "\t\tTraining Accuracy: 83.00%\t Validation Accuracy: 78.86%\n",
            "\n",
            "Epoch: 5\n",
            "\t\tTraining Loss: 1.1442 \tValidation Loss: 1.2279\n",
            "\t\tTraining AELoss: 0.6601 \tValidation Loss: 0.5352\n",
            "\t\tTraining CLFLoss: 0.4841 \tValidation Loss: 0.6928\n",
            "\t\tTraining Accuracy: 83.17%\t Validation Accuracy: 77.36%\n",
            "\n",
            "Epoch: 6\n",
            "\t\tTraining Loss: 1.1390 \tValidation Loss: 1.2111\n",
            "\t\tTraining AELoss: 0.6597 \tValidation Loss: 0.5357\n",
            "\t\tTraining CLFLoss: 0.4792 \tValidation Loss: 0.6753\n",
            "\t\tTraining Accuracy: 83.27%\t Validation Accuracy: 78.06%\n",
            "\n",
            "Epoch: 7\n",
            "\t\tTraining Loss: 1.1366 \tValidation Loss: 1.2027\n",
            "\t\tTraining AELoss: 0.6600 \tValidation Loss: 0.5349\n",
            "\t\tTraining CLFLoss: 0.4766 \tValidation Loss: 0.6679\n",
            "\t\tTraining Accuracy: 83.29%\t Validation Accuracy: 78.50%\n",
            "\n",
            "Epoch: 8\n",
            "\t\tTraining Loss: 1.1321 \tValidation Loss: 1.2148\n",
            "\t\tTraining AELoss: 0.6609 \tValidation Loss: 0.5352\n",
            "\t\tTraining CLFLoss: 0.4713 \tValidation Loss: 0.6796\n",
            "\t\tTraining Accuracy: 83.61%\t Validation Accuracy: 78.20%\n",
            "\n",
            "Epoch: 9\n",
            "\t\tTraining Loss: 1.1324 \tValidation Loss: 1.2471\n",
            "\t\tTraining AELoss: 0.6605 \tValidation Loss: 0.5357\n",
            "\t\tTraining CLFLoss: 0.4720 \tValidation Loss: 0.7114\n",
            "\t\tTraining Accuracy: 83.54%\t Validation Accuracy: 77.12%\n",
            "\n",
            "Epoch: 10\n",
            "\t\tTraining Loss: 1.1269 \tValidation Loss: 1.2456\n",
            "\t\tTraining AELoss: 0.6605 \tValidation Loss: 0.5350\n",
            "\t\tTraining CLFLoss: 0.4664 \tValidation Loss: 0.7106\n",
            "\t\tTraining Accuracy: 83.61%\t Validation Accuracy: 78.24%\n",
            "\n",
            "Epoch: 11\n",
            "\t\tTraining Loss: 1.1202 \tValidation Loss: 1.2259\n",
            "\t\tTraining AELoss: 0.6606 \tValidation Loss: 0.5343\n",
            "\t\tTraining CLFLoss: 0.4596 \tValidation Loss: 0.6916\n",
            "\t\tTraining Accuracy: 83.97%\t Validation Accuracy: 78.38%\n",
            "\n",
            "Epoch: 12\n",
            "\t\tTraining Loss: 1.1175 \tValidation Loss: 1.2194\n",
            "\t\tTraining AELoss: 0.6602 \tValidation Loss: 0.5351\n",
            "\t\tTraining CLFLoss: 0.4574 \tValidation Loss: 0.6843\n",
            "\t\tTraining Accuracy: 84.03%\t Validation Accuracy: 78.46%\n",
            "\n",
            "Epoch: 13\n",
            "\t\tTraining Loss: 1.1135 \tValidation Loss: 1.2290\n",
            "\t\tTraining AELoss: 0.6610 \tValidation Loss: 0.5361\n",
            "\t\tTraining CLFLoss: 0.4525 \tValidation Loss: 0.6929\n",
            "\t\tTraining Accuracy: 84.19%\t Validation Accuracy: 77.66%\n",
            "\n",
            "Epoch: 14\n",
            "\t\tTraining Loss: 1.1184 \tValidation Loss: 1.2096\n",
            "\t\tTraining AELoss: 0.6605 \tValidation Loss: 0.5350\n",
            "\t\tTraining CLFLoss: 0.4579 \tValidation Loss: 0.6746\n",
            "\t\tTraining Accuracy: 84.05%\t Validation Accuracy: 79.10%\n",
            "\n",
            "Epoch: 15\n",
            "\t\tTraining Loss: 1.1055 \tValidation Loss: 1.2288\n",
            "\t\tTraining AELoss: 0.6606 \tValidation Loss: 0.5351\n",
            "\t\tTraining CLFLoss: 0.4449 \tValidation Loss: 0.6937\n",
            "\t\tTraining Accuracy: 84.49%\t Validation Accuracy: 78.28%\n",
            "\n",
            "Epoch: 16\n",
            "\t\tTraining Loss: 1.1007 \tValidation Loss: 1.2475\n",
            "\t\tTraining AELoss: 0.6598 \tValidation Loss: 0.5348\n",
            "\t\tTraining CLFLoss: 0.4409 \tValidation Loss: 0.7127\n",
            "\t\tTraining Accuracy: 84.63%\t Validation Accuracy: 78.58%\n",
            "\n",
            "Epoch: 17\n",
            "\t\tTraining Loss: 1.1051 \tValidation Loss: 1.2054\n",
            "\t\tTraining AELoss: 0.6605 \tValidation Loss: 0.5347\n",
            "\t\tTraining CLFLoss: 0.4446 \tValidation Loss: 0.6707\n",
            "\t\tTraining Accuracy: 84.34%\t Validation Accuracy: 78.40%\n",
            "\n",
            "Epoch: 18\n",
            "\t\tTraining Loss: 1.0996 \tValidation Loss: 1.2218\n",
            "\t\tTraining AELoss: 0.6602 \tValidation Loss: 0.5344\n",
            "\t\tTraining CLFLoss: 0.4393 \tValidation Loss: 0.6874\n",
            "\t\tTraining Accuracy: 84.67%\t Validation Accuracy: 78.02%\n",
            "\n",
            "Epoch: 19\n",
            "\t\tTraining Loss: 1.0990 \tValidation Loss: 1.2199\n",
            "\t\tTraining AELoss: 0.6597 \tValidation Loss: 0.5343\n",
            "\t\tTraining CLFLoss: 0.4393 \tValidation Loss: 0.6856\n",
            "\t\tTraining Accuracy: 84.66%\t Validation Accuracy: 78.48%\n",
            "\n",
            "Best epoch: 4 with loss: 1.20 and acc: 78.48%\n",
            "805.38 total seconds elapsed. 42.39 seconds per epoch.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkVJTlaWwYvn",
        "colab_type": "code",
        "outputId": "550456d0-e1ac-4607-88ca-2e713eb26851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_output, history = train(\n",
        "    model,\n",
        "    dataloaders['train'],\n",
        "    dataloaders['val'],\n",
        "    save_file_name='end2en-60-80.pkl',\n",
        "    max_epochs_stop=30,\n",
        "    n_epochs=20)\n",
        "\n",
        "history.to_csv('history60-80.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model has been trained for: 60 epochs.\n",
            "\n",
            "\n",
            "Epoch: 0\n",
            "\t\tTraining Loss: 1.0976 \tValidation Loss: 1.1865\n",
            "\t\tTraining AELoss: 0.6604 \tValidation Loss: 0.5351\n",
            "\t\tTraining CLFLoss: 0.4373 \tValidation Loss: 0.6514\n",
            "\t\tTraining Accuracy: 84.68%\t Validation Accuracy: 79.16%\n",
            "\n",
            "Epoch: 1\n",
            "\t\tTraining Loss: 1.0917 \tValidation Loss: 1.1875\n",
            "\t\tTraining AELoss: 0.6596 \tValidation Loss: 0.5344\n",
            "\t\tTraining CLFLoss: 0.4321 \tValidation Loss: 0.6532\n",
            "\t\tTraining Accuracy: 84.68%\t Validation Accuracy: 79.28%\n",
            "\n",
            "Epoch: 2\n",
            "\t\tTraining Loss: 1.0916 \tValidation Loss: 1.1933\n",
            "\t\tTraining AELoss: 0.6607 \tValidation Loss: 0.5347\n",
            "\t\tTraining CLFLoss: 0.4309 \tValidation Loss: 0.6586\n",
            "\t\tTraining Accuracy: 84.96%\t Validation Accuracy: 78.90%\n",
            "\n",
            "Epoch: 3\n",
            "\t\tTraining Loss: 1.0895 \tValidation Loss: 1.2041\n",
            "\t\tTraining AELoss: 0.6609 \tValidation Loss: 0.5341\n",
            "\t\tTraining CLFLoss: 0.4287 \tValidation Loss: 0.6700\n",
            "\t\tTraining Accuracy: 84.85%\t Validation Accuracy: 78.64%\n",
            "\n",
            "Epoch: 4\n",
            "\t\tTraining Loss: 1.0851 \tValidation Loss: 1.1977\n",
            "\t\tTraining AELoss: 0.6601 \tValidation Loss: 0.5346\n",
            "\t\tTraining CLFLoss: 0.4251 \tValidation Loss: 0.6631\n",
            "\t\tTraining Accuracy: 85.12%\t Validation Accuracy: 79.14%\n",
            "\n",
            "Epoch: 5\n",
            "\t\tTraining Loss: 1.0826 \tValidation Loss: 1.1992\n",
            "\t\tTraining AELoss: 0.6594 \tValidation Loss: 0.5344\n",
            "\t\tTraining CLFLoss: 0.4232 \tValidation Loss: 0.6648\n",
            "\t\tTraining Accuracy: 85.06%\t Validation Accuracy: 78.60%\n",
            "\n",
            "Epoch: 6\n",
            "\t\tTraining Loss: 1.0830 \tValidation Loss: 1.1958\n",
            "\t\tTraining AELoss: 0.6602 \tValidation Loss: 0.5345\n",
            "\t\tTraining CLFLoss: 0.4227 \tValidation Loss: 0.6613\n",
            "\t\tTraining Accuracy: 85.08%\t Validation Accuracy: 79.24%\n",
            "\n",
            "Epoch: 7\n",
            "\t\tTraining Loss: 1.0806 \tValidation Loss: 1.2349\n",
            "\t\tTraining AELoss: 0.6603 \tValidation Loss: 0.5341\n",
            "\t\tTraining CLFLoss: 0.4203 \tValidation Loss: 0.7008\n",
            "\t\tTraining Accuracy: 85.32%\t Validation Accuracy: 78.46%\n",
            "\n",
            "Epoch: 8\n",
            "\t\tTraining Loss: 1.0731 \tValidation Loss: 1.2222\n",
            "\t\tTraining AELoss: 0.6597 \tValidation Loss: 0.5345\n",
            "\t\tTraining CLFLoss: 0.4135 \tValidation Loss: 0.6877\n",
            "\t\tTraining Accuracy: 85.56%\t Validation Accuracy: 78.94%\n",
            "\n",
            "Epoch: 9\n",
            "\t\tTraining Loss: 1.0797 \tValidation Loss: 1.1831\n",
            "\t\tTraining AELoss: 0.6597 \tValidation Loss: 0.5375\n",
            "\t\tTraining CLFLoss: 0.4200 \tValidation Loss: 0.6457\n",
            "\t\tTraining Accuracy: 85.18%\t Validation Accuracy: 79.88%\n",
            "\n",
            "Epoch: 10\n",
            "\t\tTraining Loss: 1.0722 \tValidation Loss: 1.2055\n",
            "\t\tTraining AELoss: 0.6603 \tValidation Loss: 0.5348\n",
            "\t\tTraining CLFLoss: 0.4119 \tValidation Loss: 0.6708\n",
            "\t\tTraining Accuracy: 85.42%\t Validation Accuracy: 79.58%\n",
            "\n",
            "Epoch: 11\n",
            "\t\tTraining Loss: 1.0682 \tValidation Loss: 1.2018\n",
            "\t\tTraining AELoss: 0.6593 \tValidation Loss: 0.5340\n",
            "\t\tTraining CLFLoss: 0.4089 \tValidation Loss: 0.6678\n",
            "\t\tTraining Accuracy: 85.75%\t Validation Accuracy: 78.80%\n",
            "\n",
            "Epoch: 12\n",
            "\t\tTraining Loss: 1.0687 \tValidation Loss: 1.2207\n",
            "\t\tTraining AELoss: 0.6591 \tValidation Loss: 0.5343\n",
            "\t\tTraining CLFLoss: 0.4096 \tValidation Loss: 0.6863\n",
            "\t\tTraining Accuracy: 85.68%\t Validation Accuracy: 79.06%\n",
            "\n",
            "Epoch: 13\n",
            "\t\tTraining Loss: 1.0697 \tValidation Loss: 1.1810\n",
            "\t\tTraining AELoss: 0.6598 \tValidation Loss: 0.5340\n",
            "\t\tTraining CLFLoss: 0.4099 \tValidation Loss: 0.6470\n",
            "\t\tTraining Accuracy: 85.66%\t Validation Accuracy: 80.24%\n",
            "\n",
            "Epoch: 14\n",
            "\t\tTraining Loss: 1.0649 \tValidation Loss: 1.1997\n",
            "\t\tTraining AELoss: 0.6593 \tValidation Loss: 0.5346\n",
            "\t\tTraining CLFLoss: 0.4055 \tValidation Loss: 0.6651\n",
            "\t\tTraining Accuracy: 85.78%\t Validation Accuracy: 79.68%\n",
            "\n",
            "Epoch: 15\n",
            "\t\tTraining Loss: 1.0605 \tValidation Loss: 1.2207\n",
            "\t\tTraining AELoss: 0.6601 \tValidation Loss: 0.5345\n",
            "\t\tTraining CLFLoss: 0.4004 \tValidation Loss: 0.6863\n",
            "\t\tTraining Accuracy: 86.08%\t Validation Accuracy: 79.14%\n",
            "\n",
            "Epoch: 16\n",
            "\t\tTraining Loss: 1.0660 \tValidation Loss: 1.1756\n",
            "\t\tTraining AELoss: 0.6598 \tValidation Loss: 0.5339\n",
            "\t\tTraining CLFLoss: 0.4062 \tValidation Loss: 0.6417\n",
            "\t\tTraining Accuracy: 85.78%\t Validation Accuracy: 79.86%\n",
            "\n",
            "Epoch: 17\n",
            "\t\tTraining Loss: 1.0621 \tValidation Loss: 1.2189\n",
            "\t\tTraining AELoss: 0.6599 \tValidation Loss: 0.5338\n",
            "\t\tTraining CLFLoss: 0.4022 \tValidation Loss: 0.6851\n",
            "\t\tTraining Accuracy: 85.70%\t Validation Accuracy: 79.02%\n",
            "\n",
            "Epoch: 18\n",
            "\t\tTraining Loss: 1.0581 \tValidation Loss: 1.1909\n",
            "\t\tTraining AELoss: 0.6588 \tValidation Loss: 0.5344\n",
            "\t\tTraining CLFLoss: 0.3993 \tValidation Loss: 0.6565\n",
            "\t\tTraining Accuracy: 86.08%\t Validation Accuracy: 79.78%\n",
            "\n",
            "Epoch: 19\n",
            "\t\tTraining Loss: 1.0565 \tValidation Loss: 1.1913\n",
            "\t\tTraining AELoss: 0.6600 \tValidation Loss: 0.5354\n",
            "\t\tTraining CLFLoss: 0.3965 \tValidation Loss: 0.6559\n",
            "\t\tTraining Accuracy: 86.18%\t Validation Accuracy: 79.62%\n",
            "\n",
            "Best epoch: 16 with loss: 1.18 and acc: 79.62%\n",
            "819.08 total seconds elapsed. 43.11 seconds per epoch.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYTuYyLwWJMC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLto2uwsWtXp",
        "colab_type": "text"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB7_SMsuhmSN",
        "colab_type": "text"
      },
      "source": [
        "### Function to Evaluate Model Over All Classes\n",
        "\n",
        "The next function iterates through the testing set in order to make predictions for each image. It calculates performance for each category."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuVdxdfQquBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(output, target, topk=(1, )):\n",
        "    \"\"\"Compute the topk accuracy(s)\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        output = output.to('cuda')\n",
        "        target = target.to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        # Find the predicted classes and transpose\n",
        "        _, pred = output.topk(k=maxk, dim=1, largest=True, sorted=True)\n",
        "        pred = pred.t()\n",
        "\n",
        "        # Determine predictions equal to the targets\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "\n",
        "        # For each k, find the percentage of correct\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size).item())\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr4mmM4IhmSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, test_loader, criterionAE,criterionCLF, topk=(1, 3)):\n",
        "    \"\"\"Measure the performance of a trained PyTorch model\n",
        "\n",
        "    Params\n",
        "    --------\n",
        "        model (PyTorch model): trained cnn for inference\n",
        "        test_loader (PyTorch DataLoader): test dataloader\n",
        "        topk (tuple of ints): accuracy to measure\n",
        "\n",
        "    Returns\n",
        "    --------\n",
        "        results (DataFrame): results for each category\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    classes = []\n",
        "    losses = []\n",
        "    # Hold accuracy results\n",
        "    acc_results = np.zeros((len(test_loader.dataset), len(topk)))\n",
        "    i = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Testing loop\n",
        "        for data, targets in test_loader:\n",
        "\n",
        "            # Tensors to gpu\n",
        "            if torch.cuda.is_available():\n",
        "                data, targets = data.to('cuda'), targets.to('cuda')\n",
        "            # Raw model output\n",
        "            encoded,out = model(data)\n",
        "            # Iterate through each example\n",
        "            for pred, true in zip(out, targets):\n",
        "                # Find topk accuracy\n",
        "                acc_results[i, :] = accuracy(\n",
        "                    pred.unsqueeze(0), true.unsqueeze(0), topk)\n",
        "                classes.append(model.idx_to_class[true.item()])\n",
        "                \"\"\"\n",
        "                AEloss = criterionAE(encoded, data)\n",
        "\n",
        "                CLFloss = criterionCLF(output,target)\n",
        "                loss = weight_loss_ae*AEloss + weight_loss_clf*CLFloss\n",
        "                \"\"\"\n",
        "                # Calculate the loss\n",
        "                loss = criterionCLF(pred.view(1, 10), true.view(1))\n",
        "                losses.append(loss)\n",
        "                i += 1\n",
        "\n",
        "    # Send results to a dataframe and calculate average across classes\n",
        "    results = pd.DataFrame(acc_results, columns=[f'top{i}' for i in topk])\n",
        "    results['class'] = classes\n",
        "    results['loss'] = losses\n",
        "    results = results.groupby(classes).mean()\n",
        "\n",
        "    return results.reset_index().rename(columns={'index': 'class'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkG85Cg2oHfh",
        "colab_type": "code",
        "outputId": "1565eb86-0f9e-4df2-c1ae-384cb60ed64b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Mapping of Classes to Indexes\n",
        "#To keep track of the predictions made by the model, \n",
        "#we create a mapping of classes to indexes and indexes to classes.\n",
        "#This will let us know the actual class for a given prediction.\n",
        "\n",
        "model_output.class_to_idx = trainset.class_to_idx\n",
        "model_output.idx_to_class = {\n",
        "    idx: class_\n",
        "    for class_, idx in model_output.class_to_idx.items()\n",
        "}\n",
        "\n",
        "print(list(model_output.idx_to_class.items()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 'airplane'), (1, 'automobile'), (2, 'bird'), (3, 'cat'), (4, 'deer'), (5, 'dog'), (6, 'frog'), (7, 'horse'), (8, 'ship'), (9, 'truck')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5dIAK9qWlZV",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation History"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMOFqvAHhmSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterionAE = nn.MSELoss() \n",
        "criterionCLF = nn.CrossEntropyLoss() \n",
        "# Evaluate the model on all the training data\n",
        "results = evaluate(model_output,dataloaders['test'], criterionAE,criterionCLF)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0H0Xjcx5_TY",
        "colab_type": "code",
        "outputId": "821f8344-947b-47ed-b45e-3673df3d06b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "results # after 40 epochs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>top1</th>\n",
              "      <th>top3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>airplane</td>\n",
              "      <td>91.119691</td>\n",
              "      <td>97.683398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>automobile</td>\n",
              "      <td>90.310078</td>\n",
              "      <td>97.868217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bird</td>\n",
              "      <td>56.875000</td>\n",
              "      <td>89.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cat</td>\n",
              "      <td>63.102725</td>\n",
              "      <td>94.758910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>deer</td>\n",
              "      <td>71.595331</td>\n",
              "      <td>90.856031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>dog</td>\n",
              "      <td>72.111554</td>\n",
              "      <td>95.617530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>frog</td>\n",
              "      <td>88.176353</td>\n",
              "      <td>96.993988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>horse</td>\n",
              "      <td>85.889571</td>\n",
              "      <td>96.114519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ship</td>\n",
              "      <td>87.475538</td>\n",
              "      <td>94.520548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>truck</td>\n",
              "      <td>79.149798</td>\n",
              "      <td>96.963563</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        class       top1       top3\n",
              "0    airplane  91.119691  97.683398\n",
              "1  automobile  90.310078  97.868217\n",
              "2        bird  56.875000  89.375000\n",
              "3         cat  63.102725  94.758910\n",
              "4        deer  71.595331  90.856031\n",
              "5         dog  72.111554  95.617530\n",
              "6        frog  88.176353  96.993988\n",
              "7       horse  85.889571  96.114519\n",
              "8        ship  87.475538  94.520548\n",
              "9       truck  79.149798  96.963563"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cw9sp08zJux",
        "colab_type": "code",
        "outputId": "75cedb9b-a85e-4990-e900-13080d9d9707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "results # after 60 epochs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>top1</th>\n",
              "      <th>top3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>airplane</td>\n",
              "      <td>89.382239</td>\n",
              "      <td>96.718147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>automobile</td>\n",
              "      <td>93.992248</td>\n",
              "      <td>98.643411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bird</td>\n",
              "      <td>61.875000</td>\n",
              "      <td>88.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cat</td>\n",
              "      <td>70.230608</td>\n",
              "      <td>95.597484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>deer</td>\n",
              "      <td>67.509728</td>\n",
              "      <td>91.245136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>dog</td>\n",
              "      <td>67.729084</td>\n",
              "      <td>95.418327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>frog</td>\n",
              "      <td>81.563126</td>\n",
              "      <td>93.587174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>horse</td>\n",
              "      <td>88.752556</td>\n",
              "      <td>96.932515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ship</td>\n",
              "      <td>90.410959</td>\n",
              "      <td>98.238748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>truck</td>\n",
              "      <td>75.910931</td>\n",
              "      <td>95.546559</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        class       top1       top3\n",
              "0    airplane  89.382239  96.718147\n",
              "1  automobile  93.992248  98.643411\n",
              "2        bird  61.875000  88.333333\n",
              "3         cat  70.230608  95.597484\n",
              "4        deer  67.509728  91.245136\n",
              "5         dog  67.729084  95.418327\n",
              "6        frog  81.563126  93.587174\n",
              "7       horse  88.752556  96.932515\n",
              "8        ship  90.410959  98.238748\n",
              "9       truck  75.910931  95.546559"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk2xRdfzt4g-",
        "colab_type": "code",
        "outputId": "0bca9921-69f8-43c6-d4f3-719892dadeac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "results # after 80 epochs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>top1</th>\n",
              "      <th>top3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>airplane</td>\n",
              "      <td>85.907336</td>\n",
              "      <td>96.138996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>automobile</td>\n",
              "      <td>91.085271</td>\n",
              "      <td>99.031008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bird</td>\n",
              "      <td>60.208333</td>\n",
              "      <td>87.708333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cat</td>\n",
              "      <td>67.505241</td>\n",
              "      <td>95.387841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>deer</td>\n",
              "      <td>67.120623</td>\n",
              "      <td>90.466926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>dog</td>\n",
              "      <td>70.517928</td>\n",
              "      <td>95.219124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>frog</td>\n",
              "      <td>89.378758</td>\n",
              "      <td>95.591182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>horse</td>\n",
              "      <td>88.139059</td>\n",
              "      <td>94.683027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ship</td>\n",
              "      <td>93.150685</td>\n",
              "      <td>97.455969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>truck</td>\n",
              "      <td>87.449393</td>\n",
              "      <td>97.570850</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        class       top1       top3\n",
              "0    airplane  85.907336  96.138996\n",
              "1  automobile  91.085271  99.031008\n",
              "2        bird  60.208333  87.708333\n",
              "3         cat  67.505241  95.387841\n",
              "4        deer  67.120623  90.466926\n",
              "5         dog  70.517928  95.219124\n",
              "6        frog  89.378758  95.591182\n",
              "7       horse  88.139059  94.683027\n",
              "8        ship  93.150685  97.455969\n",
              "9       truck  87.449393  97.570850"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHWVC2Pv13s_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}